{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общее название проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _\"Детальное название проекта.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "## Part 0: Introduction\n",
    "\n",
    "### Overview\n",
    "    О чем этот датасет\n",
    "    +\n",
    "    Метаданные:\n",
    "    \n",
    "* Rank - Ranking of overall sales\n",
    "\n",
    "* Name - The games name\n",
    "\n",
    "* Year - Year of the game's release\n",
    "  \n",
    "### Assumptions\n",
    "    Пояснения/уточнения\n",
    "\n",
    "### Questions:\n",
    "     Вопросы но которые надо ответить\n",
    "\n",
    "* #### Question 1: \n",
    "* #### Question 2: \n",
    "* #### Question 3: \n",
    "\n",
    "\n",
    "## [Part 1: Import, Settings, Load Data](#Part-1:-Import,-Settings,-Load-Data.)\n",
    "* ### Import libraries, Create settings, Read data from ‘.csv’ file\n",
    "\n",
    "## [Part 2: Exploratory Data Analysis](#Part-2:-Exploratory-Data-Analysis.)\n",
    "* ### Info, Head, Describe \n",
    "* ### Observation of target variable \"...\"\n",
    "* ### Missing Data\n",
    "    * #### List of data features with missing values (visualisation: какую диаграмму, график или плот используем?) \n",
    "    * #### Filling missing values\n",
    "* ### Numerical and Categorical features\n",
    "    * #### List of Numerical and Categorical features\n",
    "    * #### Numerical features:\n",
    "        * Head\n",
    "        * Visualisation of Numerical features (какую диаграмму, график или плот используем?)\n",
    "        * Outliers (visualisation: какую диаграмму, график или плот используем?)\n",
    "        * Correlation Numerical features to the target\n",
    "\n",
    "    * #### Categorical Features:\n",
    "        * Head\n",
    "        * Visualisation of Categorical features (какую диаграмму, график или плот используем?)\n",
    "        * Convert Categorical into Numerical features\n",
    "        * Drop all old Categorical features \n",
    "        \n",
    "    * #### Correlation new features to the target. Drop all features with weak correlation to the target.\n",
    "    * #### Visualisation of all data features with strong correlation to target (visualisation: heatmap)\n",
    "\n",
    "## [Part 3: Data Wrangling and Transformation](#Part-3:-Data-Wrangling-and-Transformation.)\n",
    "* ### Multicollinearity \n",
    "* ### Standard Scaler\n",
    "* ### Creating datasets for ML part\n",
    "* ### 'Train\\Test' splitting method\n",
    "\n",
    "## [Part 4: Machine Learning](#Part-4:-Machine-Learning.)\n",
    "* ### ML Models\n",
    "* ### Build and train a models\n",
    "* ### Evaluate a models\n",
    "     * #### If regression: Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Abolute Error (MAE), R Squared\n",
    "     * #### If Classification: Classification Report and Confusion Matrix \n",
    "* ### Hyper parameters tuning (если надо)\n",
    "* ### Creating final predictions with Test set\n",
    "* ### If Classification: AUC–ROC curve (если надо)\n",
    "\n",
    "## [Conclusion](#Conclusion.)\n",
    "* ### Submission of ‘.csv’ file with predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Import, Settings, Load Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seabors as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seabors as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_VALUE_CORR = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('.csv')\n",
    "df_test = pd.read_csv('.csv')\n",
    "\n",
    "#identify target\n",
    "target = df_train['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistic - описательная статистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно увидеть типы данных и есть ли пропущенные значения\n",
    "df_train.info()\n",
    "\n",
    "# 5 первых или последних строк\n",
    "df_train.head()\n",
    "df_train.tail()\n",
    "\n",
    "# названия колонок\n",
    "df_train.collumns\n",
    "\n",
    "# много инфы по данным в сете\n",
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation of target feature - Обзор главного атрибута"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation of 'SalesPrice' distribution\n",
    "sns.distplot(train['SalePrice'], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "Смотрим:\n",
    "- сколько классов\n",
    "- хорошо ли они сбалансированы.\n",
    "    - смотрим на значения\n",
    "    - считаем процент по каждому значению\n",
    "    - визуализируем столбчатой диаграммой\n",
    "    \n",
    "Если какого-то класса больше (перекос), то нужно сбалансировать (можно разброс в несколько %):\n",
    " - oversampling - искусственно создаем примеры недостающего класса\n",
    " - undersampling - уменьшаем примеры большого класса до маленького\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for number of survived (1) and not survived (0) people\n",
    "df_train['Survived'].value_counts()\n",
    "\n",
    "# Present '0' and '1' values in %\n",
    "print('0 Not Survived: ', round(df_train['Survived'].value_counts()[0] / len(df_train) * 100, 2), '% of dataset')\n",
    "print('1 Survived: ', round(df_train['Survived'].value_counts()[1] / len(df_train) * 100, 2), '% of dataset')\n",
    "\n",
    "# Visualisation of '0' and '1' states\n",
    "colors = ['mediumseagreen', 'royalblue']\n",
    "sns.countplot('Survived', data=df_train, pallete=colors)\n",
    "plt.title('Class distributions 0 | 1', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - пропущенные или нулевые значения\n",
    "1. Находим колонки с пропущенными или нулевыми значениями\n",
    "1. Заполняем пропущенные значения(числовыми или категориальными атрибутами):\n",
    "- числовые данные - заполняем значением mean/mode/median, иногда 0\n",
    "- категориальные данные - заполняем значением 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train dataset columns with missing values\n",
    "nan_columns = [i for i in df_train.columns if df_train[i].isnull().any()]\n",
    "print(df_train.isnull().sum())\n",
    "print()\n",
    "print(f'There are {str(len(nan_columns))} with NAN values from 891 rows')\n",
    "nan_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "\n",
    "# categorical columns to fill with 'NAN'\n",
    "nan_columns_cat_fill = [\n",
    "    'Embarked',\n",
    "    'Cabin'\n",
    "]\n",
    "\n",
    "# replace 'NaN' with 'None' in these columns\n",
    "for col in nan_columns_cat_fill:\n",
    "    df_train[col].fillna('None', inplace=True)\n",
    "    df_test[col].fillna('None', inplace=True)\n",
    "    \n",
    "# numerical columns to fill\n",
    "nan_columns_dig_fill = [\n",
    "    'Age'\n",
    "]\n",
    "\n",
    "# replace 'NaN' with mean in these columns\n",
    "for col in nan_columns_dig_fill:\n",
    "    df_train[col].fillna(df_train.mean(), inplace=True)\n",
    "    df_test[col].fillna(df_train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical and Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Numerical and Categorical features - выводим кол-во атрибутов разных типов и их названия\n",
    "numerical_attrs_train = df_train.dtypes[df_train.dtypes != 'object'].index\n",
    "print('Quantity of Numerical: ', len(numerical_attrs_train))\n",
    "print()\n",
    "print(df_train[numerical_attrs_train].columns)\n",
    "\n",
    "categorical_attrs_train = df_train.dtypes[df_train.dtypes == 'object'].index\n",
    "print('Quantity of Categorical: ', len(categorical_attrs_train))\n",
    "print()\n",
    "print(df_train[categorical_attrs_train].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview first rows of numerical data\n",
    "df_train[numerical_attrs_train].head()\n",
    "\n",
    "# visualize numerical data to find outliers (выбросы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation num features to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling and Transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
